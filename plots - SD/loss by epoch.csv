epoch,val/loss,train/loss_epoch
0,0.193804458,0.150454149
1,0.193804458,0.150454149
2,0.109244652,0.143497348
3,0.186601743,0.1498072
4,0.153055176,0.145683274
5,0.093021303,0.155475646
6,0.116741821,0.143168762
7,0.127903253,0.141015619
8,0.054718003,0.148449078
9,0.171826527,0.142767429
10,0.213305771,0.141737014
11,0.191381678,0.143971041
12,0.142210588,0.150726512
13,0.139213368,0.141429037
14,0.315246552,0.15054217
15,0.14414537,0.145247146
16,0.110281713,0.152233213
17,0.070089452,0.141101763
18,0.13778238,0.146855906
19,0.276724637,0.141928971
20,0.148102432,0.143443242
21,0.075901948,0.152592912
22,0.081649743,0.142145082
23,0.109122485,0.147494748
24,0.10167522,0.142782405
25,0.138955474,0.141295806
26,0.228010282,0.138827235
27,0.092042431,0.143828034
28,0.086614676,0.135733232
29,0.182816923,0.144552231
30,0.087810375,0.140094563
31,0.206635386,0.142755091
32,0.166340366,0.145589292
33,0.111153409,0.142608166
34,0.064141817,0.151921481
35,0.119882718,0.153481886
36,0.210062936,0.141637802
37,0.127892107,0.154149681
38,0.125930458,0.145217523
39,0.181909427,0.138864025
40,0.228454724,0.142011419
